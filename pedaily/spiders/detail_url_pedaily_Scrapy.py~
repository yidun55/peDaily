#coding: utf-8

"""
  从投资界上爬取投资事件等数据
  auther: bill_cpp
  email:bill_cpp@sina.com
  date:2015/6/23
"""

from scrapy.spider import Spider
from scrapy.http import Request
from scrapy import log
import redis

import sys
reload(sys)
sys.setdefaultencoding("utf-8")

class pedaily(Spider):
    name = "pedaily_list"
    start_urls = []
    myRedis = redis.StrictRedis(host='localhost',port=6379)
    def __init__(self,redis_key,start_url):
        self.redis_key = redis_key
        self.__class__.start_urls.append(start_url)

    def parse(self, response):
        """
        extract the total pages
        """
        sel = response.selector
        try:
            total_page = sel.xpath("//div[@class='page-list page']/a[5]/text()").extract()
        except Exception,e:
            log.msg("message={m},url={url}".format(m=e, url=response.url),level=log.ERROR)
        for i in xrange(1, int(total_page)+1):
            yield Request(url+str(i)+"/", callback=self.extract_url, dont_filter=True)

    def extract_url(self, response):
        """
        extract url of detail information
        """
        sel = response.selector
        detail_url = sel.xpath(u"//table//a[text()='详情']/@href").extract()
        base_url = "http://zdb.pedaily.cn"
        try:
            detail_url = [base_url+url for url in detail_url]
        except Exception,e:
            log.msg("message={m},url={url}".format(m=e, url=response.url),level=log.ERROR)
        for url in detail_url:
            yield Request(url, callback=self.extract_detail, dont_filter=True)

    def extract_detail(self, response):
        """
        extract detail information
        """
        sel = response.selector



